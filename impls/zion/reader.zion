import list {Cons, Nil, List}
import vector {from_vector}
import parser {
  all_of_input, parse_string, many, Span, ParseState, lift, char, text, const,
  sequence, Progress, OK, Fail, skip_while, span_concat, non_empty, many1,
  signed_int, within_quotes, skip_leading, until_one_of, choice, dot_star,
  digits, span_text, not_char}
import types {
  MalBool, MalNil, MalValue, MalInt, MalFloat, MalString, MalSymbol, MalList,
  MalKeyword, MalVector, MalDict, MalError, MalEOF, MalStop, mal_nil, mal_true,
  mal_false, final, error, Continuation, Final, Error}
import itertools {take_pairs}

data Token {
  TInteger(Int)
  TKeyword(String)
  TSpecial(Char)
  TQuote(String)
  TDeref
  TQuasiAt
  TWithMeta
  TComment(String)
  TNonSpecial(String)
  TUnbalanced(String)
}

instance Str Token {
  fn str(t) => match t {
    TInteger(i)     => "TInteger('${i}')"
    TKeyword(k)     => "TKeyword('${k}')"
    TSpecial(ch)    => "TSpecial('${ch}')"
    TDeref          => "TDeref"
    TQuote(q)       => "TQuote(${q})"
    TQuasiAt        => "TQuasiAt"
    TWithMeta       => "TWithMeta"
    TComment(c)     => "TComment(${c})"
    TNonSpecial(ns) => "TNonSpecial(${ns})"
    TUnbalanced(c)  => "TUnbalanced(${c})"
  }
}

fn either_quotes(either) => match either {
  Left(unclosed) => TUnbalanced(unclosed)
  Right(spans) => TQuote(strconcat(spans))
}

let escaped_backslash = lift(const("\\"), text("\\\\", False))
let escaped_newline = lift(const("\n"), text("\\n", False))
let escaped_quote = lift(const("\""), text("\\\"", False))
let quoted_string = lift(either_quotes, within_quotes(
    '"',
    many(choice([
      escaped_newline,
      escaped_backslash,
      escaped_quote,
      lift(str, not_char('"')),
    ])))) as fn (ParseState) Progress ParseState Token

let comma_or_space = |x| => x == ',' or isspace(x)
fn skip_delimiters(ps ParseState) ParseState {
  return skip_while(ps, comma_or_space)
}

let skip_space_before = |parser| => |ps| => parser(skip_delimiters(ps))
fn skip_space_after(parser) {
  return |ps| => match parser(ps) {
    OK(ps, content) => OK(skip_delimiters(ps), content)
    Fail => Fail
  }
}

let comment_eol = lift(.span_concat.str.TComment, sequence([char(';'), until_one_of("\n")]))
let quasi_at = lift(const(TQuasiAt), text("~@", False /*skip_leading_space*/))
let with_meta = lift(const(TWithMeta), text("^", False /*skip_leading_space*/))
let deref = lift(const(TDeref), text("@", False /*skip_leading_space*/))

fn special(ps ParseState) Progress ParseState Token {
  let ParseState(content, index) = ps
  if index < len(content) and content[index] in "[]{}()'`~^@" {
    return OK(ParseState(content, index + 1), TSpecial(content[index]))
  } else {
    return Fail
  }
}

let keyword = lift(.str.TKeyword, skip_leading(':', non_empty(non_special_chars)))
let non_special_chars = until_one_of(" \r\n\t[]{}('\"`,;)")
let non_special = lift(.str.TNonSpecial, non_empty(non_special_chars))
let tokenizer = all_of_input(
    skip_space_before(many1(
        skip_space_after(choice([
          lift(TInteger, signed_int),
          deref,
          quasi_at,
          with_meta,
          special,
          quoted_string,
          comment_eol,
          keyword,
          non_special,
        ]))))) as fn (ps) Progress ParseState [Token]

newtype Reader = Reader([Token], var Int)

fn next(r) Maybe Token {
  let Reader(spans, var pos) = r
  if pos >= len(spans) {
    return Nothing
  } else {
    let cur_pos = pos
    pos += 1
    return Just(spans[cur_pos])
  }
}

fn peek(r) Maybe Token {
  let Reader(spans, var pos) = r
  if pos >= len(spans) {
    return Nothing
  } else {
    return Just(spans[pos])
  }
}

fn read_str(s String) Continuation {
  if tokenizer.parse_string(s) is Just(tokens) {
    return read_form_from_tokens(tokens)
  } else {
    return "Could not find any tokens.".error
  }
}

fn read_form_from_tokens(spans) {
  assert(len(spans) > 0)
  return Reader(spans, new).read_form
}

fn is_token(reader, symbol) Bool { 
  if reader.peek is Just(TSpecial(s)) {
    if s == symbol {
      reader.next!
      return True
    }
  }
  return False
}

let is_rparen = .is_token(')')
let is_rsquare = .is_token(']')
let is_rcurly = .is_token('}')

fn read_quoted(reader, kind) => match reader.read_form {
  Final(form) => MalList(Cons(MalSymbol(kind), Cons(form, Nil))).final
  other       => other
}

fn read_with_meta(reader) => match reader.read_form {
  Final(meta_data) => match reader.read_form {
    Final(form) => MalList(Cons(MalSymbol("with-meta"), Cons(form, Cons(meta_data, Nil)))).final
    other => other
  }
  other => other
}

fn mkdict(values) {
  if len(values) % 2 != 0 {
    return "Found an odd number of atoms in a hashmap!".error
  }
  let dict = {}
  for (key, value) in values.take_pairs {
    match key {
      MalKeyword(k) => dict["k|${k}"] = value
      MalString(s)  => dict["z|${s}"] = value
      MalInt(s)     => dict["i|${s}"] = value
      MalNil        => dict["nil"] = value
      _             => return "Hashmaps only accept keywords, integers, and strings as keys. (Got ${key})".error
    }
  }
  return MalDict(dict).final
}

fn read_form(reader) Continuation { 
  while reader.next is Just(token) {
    if token is TComment(_) {
      continue
    }
    return match token {
      TInteger(i)      => MalInt(i).final
      TKeyword(kwd)    => MalKeyword(":${kwd}").final
      TDeref           => reader.read_quoted("deref")
      TQuasiAt         => reader.read_quoted("splice-unquote")
      TWithMeta        => reader.read_with_meta
      TQuote(s)        => MalString(s).final
      TSpecial('(')    => reader.read_list(.from_vector.MalList.Final, is_rparen)
      TSpecial('[')    => reader.read_list(.MalVector.Final, is_rsquare)
      TSpecial('\'')   => reader.read_quoted("quote")
      TSpecial('`')    => reader.read_quoted("quasiquote")
      TSpecial('{')    => reader.read_list(mkdict, is_rcurly)
      TSpecial('~')    => reader.read_quoted("unquote")
      TSpecial(sp)     => "Unrecognized special token: ${sp}".error
      TUnbalanced(u)   => "unbalanced token encountered: ${u}".error
      TComment(_)      => "Not reached".error
      TNonSpecial(sym) => read_atom(sym)
    }
  }
  return "end of input encountered".error
}

fn unescape_quoted_span(span Span) String {
  let s = str(span)
  assert(s[0] == '"')
  assert(s[len(s)-1] == '"')
  return s[1:len(s)-1].replace("\\\\", "\\").replace("\\\"", "\"")
}

fn read_atom(atom String) Continuation {
  if atom == "nil" {
    return mal_nil
  } else if atom == "false" {
    return mal_false
  } else if atom == "true" {
    return mal_true
  } else {
    return MalSymbol(atom).final
  }
}

fn read_list(reader, ctor, is_closing_symbol) Continuation {
  let result = []
  while not is_closing_symbol(reader) {
    match reader.read_form {
      Final(value) => result.append(value)
      Error(MalEOF) => return "Premature end of input while reading list.".error
      otherwise => return otherwise
    }
  }
  return ctor(result)
}
